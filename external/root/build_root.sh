#!/bin/bash

##############################################################################
##### BULK OF THIS TAKEN FROM JLAB FARM /apps/root/6.28.02/build_root.sh #####
##############################################################################
#
# This will build root on an ifarm machine that can then be copied to
# to the /apps directory via an admin machine with write priviliges
# such as:
#
#    cni-rhel7    or    cni-rhel8
#
#
# This includes support for SOFIE as requested in ServiceNow incident
# INC0097641. To do this, it requires Google protobuf to be compiled
# and for numpy and pytorch to be installed for python. Both of these
# are done automatically by this script. The numpy and pytorch packages
# are installed in a virtual environment created by this script and
# instructions for sourcing it are automatically added to the scripts
# setROOT_CUE-gcc${GCC_VERS}.(c)sh (also generated by this script).
#
# Building on ifarm is considerably faster than on the admin machine
# so it is worthwhile (and maybe necessary) to do. Once complete,
# one may copy it to the appropriate /apps directory using one of
# the above mentioned nodes which mounts it as writable. The admin
# machines, however, do not mount the scicomp work disks so you need
# to use something like /u/scigroup as a temporary intermediary.
#
# For example:
#
#  ./build_root.sh
#  mkdir -p /u/scigroup/halld/${ROOT_VERS}
#  cp -rp * /u/scigroup/halld/${ROOT_VERS}
#
#  # Log into cni-rhel7
#
#  mv /u/scigroup/halld/${ROOT_VERS} /apps/root/
#
#
# Once it is installed, source the setROOT_CUE.(c)sh for your shell to
# set up ROOT and run the benchmarks.C script:
#
#   source setROOT_CUE.csh
#   module load gcc/${GCC_VERS}
#   source /apps/root/${ROOT_VERS}/${PYTHON_VENV_DIR}/bin/activate.csh
#   root -l $ROOTSYS/tutorials/legacy/benchmarks.C
#
#
# Check python works correctly by verifying ROOT imports cleanly:
#
#   python3
#   >>> import ROOT
#
#
# The SOFIE support can be checked with:
#
# python3 $ROOTSYS/tutorials/tmva/pytorch/ClassificationPyTorch.py
# python3 $ROOTSYS/tutorials/tmva/pytorch/MulticlassPyTorch.py
# python3 $ROOTSYS/tutorials/tmva/pytorch/RegressionPyTorch.py
# python3 $ROOTSYS/tutorials/tmva/pytorch/ApplicationClassificationPyTorch.py
# python3 $ROOTSYS/tutorials/tmva/pytorch/ApplicationRegressionPyTorch.py
#
# Issues can be posted to the JLab ServiceNow or sent to davidl@jlab.org
#
#-----------------------------------------------------------------------------

# Specify ROOT, compiler, python, and cmake versions
conda activate PyAmpTools # activate the conda environment
export ROOT_VERS=6.28.06
export GCC_VERS=9.3.0
export PYTHON_VERS=$(python -V 2>&1 | grep -Po '(?<=Python )(.+)')
export CMAKE_VERS=3.23.2
export protbuf_VERSION=21.12
export CXX_STANDARD=17
eval `/usr/bin/modulecmd bash load gcc/${GCC_VERS}` # load gcc if on JLab ifarm

# Extra flags for building ROOT from source
export EXTRA_CMAKE_FLAGS="-Droofit=Off \
                          -Dtmva=Off \
                            "

# Load GPU info, default is for JLab ifarm
# eval `/usr/bin/modulecmd bash load cuda`
# export CUDA_INSTALL_PATH=/apps/cuda/11.4.2/
# export GPU_ARCH=75 # Use compute capability matching your GPU, lower than capable versions will have penalized performance
### ROOT > v6.20.06 does not require CXX and CUDA to have same standard
# CUDA_ARCHITECTURES must match
# export EXTRA_CMAKE_FLAGS="-Dcuda=On \
#                             -DCMAKE_CXX_STANDARD=17 \
#                             -DCMAKE_CUDA_STANDARD=17 \
#                             -DCMAKE_CUDA_ARCHITECTURES=$GPU_ARCH \
#                             -DCMAKE_CUDA_HOST_COMPILER=`which g++` \
                            # "

#-----------------------------------------------------------------------------
# Should not need to edit below this line (unless modifying root build flags)

export CXX=`which g++`
export CC=`which gcc`
export CMAKE=/u/apps/cmake/${CMAKE_VERS}/bin/cmake


echo "VERSIONS:"
echo "----------------"
echo "ROOT:   ${ROOT_VERS}"
echo "GCC:    ${GCC_VERS}"
echo "CMAKE:  ${CMAKE_VERS}"
echo "PYTHON: ${PYTHON_VERS}"
echo "----------------"
echo ""
echo "CXX=${CXX}"
echo "CC=${CC}"
echo "CMAKE=${CMAKE}"

export LOG="root-v${ROOT_VERS}-gcc${GCC_VERS}.log"
touch $LOG

# Record all commands to log file
set -x

# Grab protobuf source if needed
export Protobuf_ROOT=${PWD}/protobuf/protobuf-${protbuf_VERSION}
if [ ! -d ${Protobuf_ROOT} ]; then
    mkdir -p ${PWD}/protobuf
    cd ${PWD}/protobuf
    #curl -O https://github.com/protocolbuffers/protobuf/archive/refs/tags/v${protbuf_VERSION}.zip
    curl -o v${protbuf_VERSION}.zip  https://codeload.github.com/protocolbuffers/protobuf/zip/refs/tags/v21.12
    unzip v${protbuf_VERSION}.zip
    mv protobuf-${protbuf_VERSION} protobuf-${protbuf_VERSION}.src
    ${CMAKE} -S protobuf-${protbuf_VERSION}.src -B protobuf-${protbuf_VERSION}.build \
    -DCMAKE_INSTALL_PREFIX=${Protobuf_ROOT} \
    -DCMAKE_CXX_STANDARD=${CXX_STANDARD} \
    -Dprotobuf_BUILD_TESTS=OFF \
    -DCMAKE_CXX_FLAGS=-fPIC \
    -DCMAKE_C_FLAGS=-fPIC \
    |& tee -a ${LOG}
    nice ${CMAKE} --build protobuf-${protbuf_VERSION}.build --target install -- -j24 |& tee -a ${LOG}
    cd -
else
    echo "Using existing protobuf directory: ${Protobuf_ROOT}"
fi
#export Protobuf_INCLUDE_DIR=${Protobuf_ROOT}/include
#export Protobuf_LIBRARIES=${Protobuf_ROOT}/lib64

# Grab source if needed
if [ ! -d root-${ROOT_VERS}.src ]; then
    curl -O https://root.cern/download/root_v${ROOT_VERS}.source.tar.gz |& tee -a ${LOG}
    tar xzf root_v${ROOT_VERS}.source.tar.gz |& tee -a ${LOG}
    mv root-${ROOT_VERS} root-${ROOT_VERS}.src |& tee -a ${LOG}
else
    echo "Using existing source directory: root-${ROOT_VERS}.src"
fi



# Configure if needed
if [ ! -d root-${ROOT_VERS}-gcc${GCC_VERS}.build ]; then
    ${CMAKE} -S root-${ROOT_VERS}.src -B root-${ROOT_VERS}-gcc${GCC_VERS}.build \
        -DCMAKE_CXX_STANDARD=${CXX_STANDARD} \
        -DCMAKE_INSTALL_PREFIX=root-${ROOT_VERS}-gcc${GCC_VERS} \
        -Dbuiltin_glew=ON \
        -DProtobuf_INCLUDE_DIR=${Protobuf_ROOT}/include \
        ${EXTRA_CMAKE_FLAGS} \
        |& tee -a ${LOG}
else
    echo "Skipping configuration and using existing root-${ROOT_VERS}-gcc${GCC_VERS}.build"
    echo "(Remove directory root-${ROOT_VERS}-gcc${GCC_VERS}.build and rerun if reconfiguration needed)"
fi

# Build if needed
if [ ! -d root-${ROOT_VERS}-gcc${GCC_VERS} ]; then
    nice ${CMAKE} --build root-${ROOT_VERS}-gcc${GCC_VERS}.build --target install -- -j24 |& tee -a ${LOG}
else
    echo "Skipping build and using existing root-${ROOT_VERS}-gcc${GCC_VERS}"
    echo "(Remove directory root-${ROOT_VERS}-gcc${GCC_VERS} and rerun if rebuild needed)"
fi

# Turn off command echo
set +x

# Create bash setenv file
export SETENV="thisroot.sh"
rm -f $SETENV
touch $SETENV
echo "#!/bin/bash" >> $SETENV
echo "" >> $SETENV
echo "echo \"\"" >> $SETENV
echo "echo \"[LOADED ROOT] ROOT ${ROOT_VERS} was compiled with gcc ${GCC_VERS} and python ${PYTHON_VERS}\"" >> $SETENV
echo "" >> $SETENV
echo "module load gcc/${GCC_VERS}" >> $SETENV
echo "source \$1/root-${ROOT_VERS}-gcc${GCC_VERS}/bin/thisroot.sh" >> $SETENV
echo "" >> $SETENV


# Create tcsh setenv file
export SETENV="thisroot.csh"
rm -f $SETENV
touch $SETENV
echo "#!/bin/tcsh -f" >> $SETENV
echo "" >> $SETENV
echo "echo \"\"" >> $SETENV
echo "echo \"[LOADED ROOT] ROOT ${ROOT_VERS} was compiled with gcc ${GCC_VERS} and python ${PYTHON_VERS}\"" >> $SETENV
echo "" >> $SETENV
echo "module load gcc/${GCC_VERS}" >> $SETENV
echo "source \$1/root-${ROOT_VERS}-gcc${GCC_VERS}/bin/thisroot.csh" >> $SETENV
echo "" >> $SETENV
